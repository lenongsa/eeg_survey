{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T14:34:42.343850Z",
     "start_time": "2020-11-20T14:34:38.297075Z"
    }
   },
   "outputs": [],
   "source": [
    "###libraries\n",
    "\n",
    "#Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#Time series transformers\n",
    "from pyts.multivariate.classification import MultivariateClassifier\n",
    "from pyts.multivariate.transformation import WEASELMUSE\n",
    "from pyts.classification import KNeighborsClassifier\n",
    "from pywt import wavedec\n",
    "import pyeeg\n",
    "\n",
    "#Classifiers\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "#Deep Learning\n",
    "import mcfly\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "\n",
    "#Auxiliary Functions\n",
    "from aux_functions import ResampleLinear1D\n",
    "from aux_functions import get_features\n",
    "\n",
    "#System Settings\n",
    "import sys\n",
    "import os\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T14:35:13.475200Z",
     "start_time": "2020-11-20T14:35:05.218906Z"
    }
   },
   "outputs": [],
   "source": [
    "###Read the data\n",
    "dataset = 'DEAP'\n",
    "response = 'y_valence'\n",
    "\n",
    "#Train and testing datasets\n",
    "with open(os.path.join('Datasets_clean', 'DEAP', 'clean_data.pkl'), 'rb') as handle:\n",
    "    clean_data = pickle.load(handle)\n",
    "\n",
    "#Create train/test splits for cross-validation\n",
    "subjects = np.array(list(clean_data.keys()))\n",
    "\n",
    "train_index = []\n",
    "test_index = []\n",
    "\n",
    "skf = KFold(n_splits=10)\n",
    "for train, test in skf.split(subjects):\n",
    "    train_index.append(train)\n",
    "    test_index.append(test)\n",
    "    \n",
    "#Optimal Hyperparameters\n",
    "with open('hyperparameters.json') as json_file:\n",
    "    hyperparameters = json.load(json_file)[dataset]\n",
    "    \n",
    "#Create scores dict\n",
    "scores = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T10:58:11.813414Z",
     "start_time": "2020-11-04T10:58:11.801859Z"
    }
   },
   "outputs": [],
   "source": [
    "#Function to train the Neural Networks\n",
    "def dl_func(dl_type,\n",
    "            X_train_dl, \n",
    "            y_train_dl,\n",
    "            X_val_dl,\n",
    "            y_val_dl,\n",
    "            X_test_dl,\n",
    "            y_test_dl):\n",
    "    \n",
    "    #Validate diferent architectures\n",
    "    num_of_candidate_models = 10\n",
    "    random_search_epoches = 100\n",
    "    random_search_es = 30\n",
    "    best_model_epoches = 200\n",
    "    best_model_es = 30\n",
    "    \n",
    "    for mod_type in [dl_type]:\n",
    "\n",
    "        #Create architectures\n",
    "        num_classes = y_train_dl.shape[1]\n",
    "        metric = 'accuracy'\n",
    "        models = mcfly.modelgen.generate_models(X_train_dl.shape,\n",
    "                                                number_of_classes=num_classes,\n",
    "                                                number_of_models = num_of_candidate_models,\n",
    "                                                model_types = [mod_type])\n",
    "\n",
    "        #Save intermediate results\n",
    "        resultpath = 'temp'\n",
    "        outputfile = os.path.join(resultpath, 'modelcomparison_{}_{}.json'.format(mod_type,dataset))\n",
    "\n",
    "        #Find best architecture\n",
    "        histories, val_accuracies, val_losses = mcfly.find_architecture.train_models_on_samples(X_train_dl, y_train_dl,\n",
    "                                                                                                X_val_dl, y_val_dl,\n",
    "                                                                                                models,\n",
    "                                                                                                nr_epochs=random_search_epoches,\n",
    "                                                                                                subset_size=None,\n",
    "                                                                                                verbose=False,\n",
    "                                                                                                outputfile=outputfile,\n",
    "                                                                                                early_stopping_patience=random_search_es\n",
    "                                                                                                )\n",
    "\n",
    "        #Select and train best architecture\n",
    "        best_model_index = np.argmax(val_accuracies)\n",
    "        best_model, best_params, best_model_types = models[best_model_index]\n",
    "\n",
    "        es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=best_model_es)\n",
    "        mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "        history = best_model.fit(X_train_dl, y_train_dl,\n",
    "                                 epochs=best_model_epoches, validation_data=(X_val_dl, y_val_dl),\n",
    "                                 callbacks = [es,mc])\n",
    "\n",
    "        #Accuracy in test dataset\n",
    "        saved_model = load_model('best_model.h5')\n",
    "        return saved_model.evaluate(X_test_dl, y_test_dl, verbose = False)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-04T10:29:06.025Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Train CNN and InceptionTime architectures\n",
    "accuracies_cnn = []\n",
    "accuracies_it = []\n",
    "\n",
    "for train_ind, test_ind in zip(train_index, test_index):\n",
    "    X_train = np.vstack([clean_data[key]['X'] for key in subjects[train_ind]])\n",
    "    y_train = np.hstack([clean_data[key][response] for key in subjects[train_ind]])\n",
    "    \n",
    "    X_test = np.vstack([clean_data[key]['X'] for key in subjects[test_ind]])\n",
    "    y_test = np.hstack([clean_data[key][response] for key in subjects[test_ind]])\n",
    "\n",
    "    #Create train, validation and test sets for DL\n",
    "    LE = LabelEncoder()\n",
    "    skf_train_val = StratifiedKFold(n_splits=5)\n",
    "\n",
    "    for train_index, val_index in skf_train_val.split(X_train, y_train):\n",
    "        train_index = train_index\n",
    "        val_index = val_index\n",
    "\n",
    "    X_train_val = X_train.copy()\n",
    "\n",
    "    X_train_dl = X_train_val[train_index].copy()\n",
    "    X_train_dl = np.transpose(X_train_dl, (0,2,1))\n",
    "    y_train_dl = y_train[train_index].copy()\n",
    "    y_train_dl = to_categorical(LE.fit_transform(y_train_dl))\n",
    "\n",
    "    X_val_dl = X_train_val[val_index].copy()\n",
    "    X_val_dl = np.transpose(X_val_dl, (0,2,1))\n",
    "    y_val_dl = y_train[val_index].copy()\n",
    "    y_val_dl = to_categorical(LE.transform(y_val_dl))\n",
    "\n",
    "    X_test_dl = np.transpose(X_test, (0,2,1))\n",
    "    y_test_dl = to_categorical(LE.transform(y_test))\n",
    "    \n",
    "    #Define the networks\n",
    "    acc_cnn = dl_func('CNN',\n",
    "                     X_train_dl, \n",
    "                     y_train_dl,\n",
    "                     X_val_dl,\n",
    "                     y_val_dl,\n",
    "                     X_test_dl,\n",
    "                     y_test_dl)\n",
    "    \n",
    "    acc_it = dl_func('InceptionTime',\n",
    "                     X_train_dl, \n",
    "                     y_train_dl,\n",
    "                     X_val_dl,\n",
    "                     y_val_dl,\n",
    "                     X_test_dl,\n",
    "                     y_test_dl)\n",
    "\n",
    "    accuracies_cnn.append(acc_cnn)\n",
    "    accuracies_it.append(acc_it)\n",
    "\n",
    "#Save the mean and std of accuracies of the models over the splits\n",
    "scores['dl_cnn'] = [np.mean(accuracies_cnn), np.std(accuracies_cnn)]\n",
    "scores['dl_it'] = [np.mean(accuracies_it), np.std(accuracies_it)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DTW + 1-Knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T10:52:04.753932Z",
     "start_time": "2020-11-04T10:29:11.041167Z"
    }
   },
   "outputs": [],
   "source": [
    "dtw_acc = []\n",
    "\n",
    "for train_ind, test_ind in zip(train_index, test_index):\n",
    "    X_train = np.vstack([clean_data[key]['X'] for key in subjects[train_ind]])\n",
    "    y_train = np.hstack([clean_data[key][response] for key in subjects[train_ind]])\n",
    "    \n",
    "    X_test = np.vstack([clean_data[key]['X'] for key in subjects[test_ind]])\n",
    "    y_test = np.hstack([clean_data[key][response] for key in subjects[test_ind]])\n",
    "    \n",
    "    X_train = np.apply_along_axis(ResampleLinear1D, axis = 2, arr = X_train)\n",
    "    X_test = np.apply_along_axis(ResampleLinear1D, axis = 2, arr = X_test)\n",
    "    \n",
    "    dtw_knn = MultivariateClassifier(KNeighborsClassifier(metric = 'dtw_itakura',\n",
    "                                                          n_jobs = -1,\n",
    "                                                          metric_params = {'max_slope' : 2}))\n",
    "    \n",
    "    dtw_knn.fit(X_train,y_train)\n",
    "    acc = dtw_knn.score(X_test,y_test)\n",
    "    dtw_acc.append(acc)\n",
    "    \n",
    "scores['dtw_knn'] = [np.mean(dtw_acc), np.std(dtw_acc)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WEASELMUSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T15:05:12.845236Z",
     "start_time": "2020-11-20T14:35:38.922995Z"
    }
   },
   "outputs": [],
   "source": [
    "#Accuracies\n",
    "accuracies_lr = []\n",
    "accuracies_rf = []\n",
    "accuracies_svc = []\n",
    "accuracies_lgbm = []\n",
    "\n",
    "#Train and evaluate the models over the stratified splits\n",
    "for train_ind, test_ind in zip(train_index, test_index):\n",
    "    print(i)\n",
    "    i = i+1\n",
    "    X_train = np.vstack([clean_data[key]['X'] for key in subjects[train_ind]])\n",
    "    y_train = np.hstack([clean_data[key][response] for key in subjects[train_ind]])\n",
    "    \n",
    "    X_test = np.vstack([clean_data[key]['X'] for key in subjects[test_ind]])\n",
    "    y_test = np.hstack([clean_data[key][response] for key in subjects[test_ind]])\n",
    "\n",
    "    #wm + lr\n",
    "    wm = WEASELMUSE(word_size = hyperparameters['wm_lr']['word_size'], \n",
    "                    n_bins = hyperparameters['wm_lr']['n_bins'])\n",
    "\n",
    "    logistic = LogisticRegression(solver = 'lbfgs',\n",
    "                                  multi_class = 'auto',\n",
    "                                  max_iter=3000,\n",
    "                                  C = hyperparameters['wm_lr']['C'])\n",
    "\n",
    "    clf = make_pipeline(wm, logistic)\n",
    "    clf.fit(X_train,y_train)\n",
    "    acc = clf.score(X_test,y_test)\n",
    "    accuracies_lr.append(np.round(acc,2))\n",
    "    \n",
    "    #wm + rf\n",
    "    wm = WEASELMUSE(word_size = hyperparameters['wm_rf']['word_size'], \n",
    "                    n_bins = hyperparameters['wm_rf']['n_bins'])\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators = hyperparameters['wm_rf']['n_estimators'],\n",
    "                                max_depth = hyperparameters['wm_rf']['max_depth'])\n",
    "\n",
    "    clf = make_pipeline(wm, rf)\n",
    "    clf.fit(X_train,y_train)\n",
    "    acc = clf.score(X_test,y_test)\n",
    "    accuracies_rf.append(np.round(acc,2))\n",
    "\n",
    "    #wm + svc\n",
    "    wm = WEASELMUSE(word_size = hyperparameters['wm_svc']['word_size'], \n",
    "                    n_bins = hyperparameters['wm_svc']['n_bins'])\n",
    "\n",
    "    svc = SVC(C = hyperparameters['wm_svc']['C'],\n",
    "              kernel = hyperparameters['wm_svc']['kernel'],\n",
    "              degree = hyperparameters['wm_svc']['degree'],\n",
    "              gamma = hyperparameters['wm_svc']['gamma'])\n",
    "\n",
    "    clf = make_pipeline(wm, svc)\n",
    "    clf.fit(X_train,y_train)\n",
    "    acc = clf.score(X_test,y_test)\n",
    "    accuracies_svc.append(np.round(acc,2))\n",
    "\n",
    "    #wm + lgbm\n",
    "    wm = WEASELMUSE(word_size = hyperparameters['wm_svc']['word_size'], \n",
    "                    n_bins = hyperparameters['wm_svc']['n_bins'])\n",
    "\n",
    "    def sparse_float(mat):\n",
    "        return mat.astype('float')\n",
    "    trans_sparse_float = FunctionTransformer(sparse_float, validate = False)\n",
    "\n",
    "    lgbm = LGBMClassifier(n_jobs = -1,\n",
    "                          num_leaves = hyperparameters['wm_lgbm']['num_leaves'],\n",
    "                          max_depth = hyperparameters['wm_lgbm']['max_depth'],\n",
    "                          learning_rate = hyperparameters['wm_lgbm']['learning_rate'],\n",
    "                          n_estimators = hyperparameters['wm_lgbm']['n_estimators'],\n",
    "                          min_split_gain = hyperparameters['wm_lgbm']['min_split_gain'],\n",
    "                          min_child_samples = hyperparameters['wm_lgbm']['min_child_samples'],\n",
    "                          colsample_by_tree = hyperparameters['wm_lgbm']['colsample_bytree'],\n",
    "                          reg_alpha = hyperparameters['wm_lgbm']['reg_alpha'],\n",
    "                          reg_lambda = hyperparameters['wm_lgbm']['reg_lambda'])\n",
    "\n",
    "    clf = make_pipeline(wm, trans_sparse_float, lgbm)\n",
    "    clf.fit(X_train,y_train)\n",
    "    acc = clf.score(X_test,y_test)\n",
    "    accuracies_lgbm.append(np.round(acc,2))\n",
    "    \n",
    "#Save the mean and std of accuracies of the models over the splits\n",
    "scores['wm_lr'] = [np.mean(accuracies_lr), np.std(accuracies_lr)]\n",
    "scores['wm_rf'] = [np.mean(accuracies_rf), np.std(accuracies_rf)]\n",
    "scores['wm_svc'] = [np.mean(accuracies_svc), np.std(accuracies_svc)]\n",
    "scores['wm_lgbm'] = [np.mean(accuracies_lgbm), np.std(accuracies_lgbm)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyEEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T15:36:26.429820Z",
     "start_time": "2020-11-20T15:07:45.897406Z"
    }
   },
   "outputs": [],
   "source": [
    "#Accuracies\n",
    "pyeeg_lr_acc = []\n",
    "pyeeg_rf_acc = []\n",
    "pyeeg_svc_acc = []\n",
    "pyeeg_lgbm_acc = []\n",
    "\n",
    "#Train and evaluate the models over the stratified splits\n",
    "for train_ind, test_ind in zip(train_index, test_index):\n",
    "\n",
    "    X_train = np.vstack([clean_data[key]['X'] for key in subjects[train_ind]])\n",
    "    y_train = np.hstack([clean_data[key][response] for key in subjects[train_ind]])\n",
    "    \n",
    "    X_test = np.vstack([clean_data[key]['X'] for key in subjects[test_ind]])\n",
    "    y_test = np.hstack([clean_data[key][response] for key in subjects[test_ind]])\n",
    "    \n",
    "    #Create features out of the eeg channels\n",
    "    feat_dict = {}\n",
    "\n",
    "    for df,name in zip([X_train,X_test],['X_train_pyeeg','X_test_pyeeg']):\n",
    "        feat_dict[name] = np.array([]).reshape(-1,2336)\n",
    "\n",
    "        for ind in range(0,df.shape[0]):\n",
    "            features = np.array([])\n",
    "\n",
    "            for channel in range(0,df[ind].shape[0]):\n",
    "                eeg_series = df[ind][channel]\n",
    "                \n",
    "                #Wavelet Coefficients features\n",
    "                coefs = wavedec(eeg_series, 'db4', level=4)\n",
    "                for band in coefs:\n",
    "                    features = np.hstack([features,get_features(band)])\n",
    "                \n",
    "                #Fourier Transform features\n",
    "                fft_power = pyeeg.bin_power(eeg_series, Band = [0.5,4,7,12,30,100], Fs = 256)\n",
    "                power_spectral_intensity = fft_power[0]\n",
    "                relative_intensity_ratio = fft_power[1]\n",
    "                spectral_entropy = pyeeg.spectral_entropy(eeg_series, Band = [0.5,4,7,12,30,100], Fs = 256,\n",
    "                                                          Power_Ratio = relative_intensity_ratio)\n",
    "\n",
    "                #Hjorth Parameters features\n",
    "                hjorth = pyeeg.hjorth(eeg_series)\n",
    "                hjorth_mob = hjorth[0]\n",
    "                hjorth_comp = hjorth[1]\n",
    "\n",
    "                features = np.hstack([features, power_spectral_intensity, relative_intensity_ratio,\n",
    "                                      hjorth_mob, hjorth_comp, spectral_entropy])\n",
    "\n",
    "\n",
    "            feat_dict[name] = np.vstack([feat_dict[name],features])\n",
    "\n",
    "    #Convert dictionary of features into numpy arrays\n",
    "    X_train_pyeeg = feat_dict['X_train_pyeeg'].copy()\n",
    "    X_test_pyeeg = feat_dict['X_test_pyeeg'].copy()\n",
    "    \n",
    "    X_train_pyeeg = np.nan_to_num(X_train_pyeeg)\n",
    "    X_test_pyeeg = np.nan_to_num(X_test_pyeeg)\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train_pyeeg)\n",
    "    X_train_pyeeg = scaler.transform(X_train_pyeeg)\n",
    "    X_test_pyeeg = scaler.transform(X_test_pyeeg)\n",
    "    \n",
    "    #pyeeg + lr\n",
    "    logistic = LogisticRegression(solver = 'lbfgs',\n",
    "                                  multi_class = 'auto',\n",
    "                                  max_iter=3000,\n",
    "                                  C = hyperparameters['pyeeg_lr']['C'])\n",
    "\n",
    "    logistic.fit(X_train_pyeeg,y_train)\n",
    "    acc = logistic.score(X_test_pyeeg,y_test)\n",
    "    pyeeg_lr_acc.append(np.round(acc,2).copy())\n",
    "    \n",
    "    #pyeeg + rf\n",
    "    rf = RandomForestClassifier(n_estimators = hyperparameters['pyeeg_rf']['n_estimators'],\n",
    "                                max_depth = hyperparameters['pyeeg_rf']['max_depth'])\n",
    "\n",
    "    rf.fit(X_train_pyeeg,y_train)\n",
    "    acc = rf.score(X_test_pyeeg,y_test)\n",
    "    pyeeg_rf_acc.append(np.round(acc,2).copy())\n",
    "    \n",
    "    #pyeeg + svc\n",
    "    svc = SVC(C = hyperparameters['pyeeg_svc']['C'],\n",
    "              kernel = hyperparameters['pyeeg_svc']['kernel'],\n",
    "              degree = hyperparameters['pyeeg_svc']['degree'],\n",
    "              gamma = hyperparameters['pyeeg_svc']['gamma'])\n",
    "\n",
    "    clf = make_pipeline(svc)\n",
    "    clf.fit(X_train_pyeeg,y_train)\n",
    "    acc = clf.score(X_test_pyeeg,y_test)\n",
    "    pyeeg_svc_acc.append(np.round(acc,2).copy())\n",
    "\n",
    "    \n",
    "    #pyeeg + lgbm\n",
    "    def sparse_float(mat):\n",
    "        return mat.astype('float')\n",
    "    trans_sparse_float = FunctionTransformer(sparse_float, validate = False)\n",
    "\n",
    "    lgbm = LGBMClassifier(n_jobs = -1,\n",
    "                          num_leaves = hyperparameters['pyeeg_lgbm']['num_leaves'],\n",
    "                          max_depth = hyperparameters['pyeeg_lgbm']['max_depth'],\n",
    "                          learning_rate = hyperparameters['pyeeg_lgbm']['learning_rate'],\n",
    "                          n_estimators = hyperparameters['pyeeg_lgbm']['n_estimators'],\n",
    "                          min_split_gain = hyperparameters['pyeeg_lgbm']['min_split_gain'],\n",
    "                          min_child_samples = hyperparameters['pyeeg_lgbm']['min_child_samples'],\n",
    "                          colsample_by_tree = hyperparameters['pyeeg_lgbm']['colsample_bytree'],\n",
    "                          reg_alpha = hyperparameters['pyeeg_lgbm']['reg_alpha'],\n",
    "                          reg_lambda = hyperparameters['pyeeg_lgbm']['reg_lambda'])\n",
    "\n",
    "    clf = make_pipeline(trans_sparse_float, lgbm)\n",
    "    clf.fit(X_train_pyeeg,y_train)\n",
    "    acc = clf.score(X_test_pyeeg,y_test)\n",
    "    pyeeg_lgbm_acc.append(np.round(acc,2).copy())\n",
    "\n",
    "#Save the mean and std of accuracies of the models over the splits\n",
    "scores['pyeeg_lr'] = [np.mean(pyeeg_lr_acc), np.std(pyeeg_lr_acc)]\n",
    "scores['pyeeg_rf'] = [np.mean(pyeeg_rf_acc), np.std(pyeeg_rf_acc)]\n",
    "scores['pyeeg_svc'] = [np.mean(pyeeg_svc_acc), np.std(pyeeg_svc_acc)]\n",
    "scores['pyeeg_lgbm'] = [np.mean(pyeeg_lgbm_acc), np.std(pyeeg_lgbm_acc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-04T10:29:06.038Z"
    }
   },
   "outputs": [],
   "source": [
    "#Salva scores\n",
    "if not os.path.exists(os.path.join('results')):\n",
    "    os.makedirs(os.path.join('results'))\n",
    "\n",
    "results = pd.Series({'DTW + 1NN' : scores['dtw_knn'][0],\n",
    "                     'WM + LR' : scores['wm_lr'][0],\n",
    "                     'WM + RF' : scores['wm_rf'][0],\n",
    "                     'WM + SVM' : scores['wm_svc'][0],\n",
    "                     'WM + GBT' : scores['wm_lgbm'][0],\n",
    "                     'FS + LR' : scores['pyeeg_lr'][0],\n",
    "                     'FS + RF' : scores['pyeeg_rf'][0],\n",
    "                     'FS + SVM' : scores['pyeeg_svc'][0],\n",
    "                     'FS + GBT' : scores['pyeeg_lgbm'][0],\n",
    "                     'InceptionTime' : scores['dl_it'][0],\n",
    "                     'CNN' : scores['dl_cnn'][0]})\n",
    "\n",
    "results.to_csv('results/Scores_{}.csv'.format(dataset), index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_survey",
   "language": "python",
   "name": "eeg_survey"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
