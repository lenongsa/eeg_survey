{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean the raw EEG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T13:18:37.492538Z",
     "start_time": "2020-11-26T13:18:37.488191Z"
    }
   },
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "\n",
    "from aux_functions import timeseries_to_pandas\n",
    "from aux_functions import pandas_to_numpy\n",
    "\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alcoholism_S1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T15:51:39.442533Z",
     "start_time": "2020-11-25T15:51:23.941458Z"
    }
   },
   "outputs": [],
   "source": [
    "#Read the csv files and concatenate them into a single dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for folder in ['SMNI_CMI_TRAIN', 'SMNI_CMI_TEST']:\n",
    "    files = os.listdir(os.path.join('Datasets_raw', 'Alcoholism_S1', folder))\n",
    "    files = [file for file in files if file.endswith('.csv')]\n",
    "    \n",
    "    for file in files:\n",
    "        data = pd.read_csv(os.path.join('Datasets_raw', 'Alcoholism_S1', folder, file))\n",
    "        df = pd.concat([df, data])\n",
    "        \n",
    "df = df.sort_values(['name', 'trial number', 'channel', 'sample num'])\n",
    "df = df[['name', 'subject identifier', 'matching condition', 'trial number',\n",
    "         'channel', 'sample num', 'sensor value']]\n",
    "\n",
    "#Limit the trials only to those where the matching condition is S1\n",
    "df = df[df['matching condition'] == 'S1 obj']\n",
    "\n",
    "#Create a dictionary to store, for each subject, a numpy array of all his trials \n",
    "#in the format (n_trials, n_channels, n_timesteps), and a numpy array with the \n",
    "#identifier of the subject ('c' for control, 'a' for alcoholic) for each\n",
    "#of his trials\n",
    "\n",
    "subjects = {}\n",
    "\n",
    "for subject in df.name.unique():\n",
    "    subjects[subject] = {}\n",
    "    trials = []\n",
    "    subject_data = df[df.name == subject]\n",
    "    \n",
    "    for trial in subject_data['trial number'].unique():\n",
    "        channels = []\n",
    "        trial_data = subject_data[subject_data['trial number'] == trial]\n",
    "    \n",
    "        for channel in trial_data['channel'].unique():\n",
    "            channel_data = list(trial_data.loc[trial_data['channel'] == channel, 'sensor value'])\n",
    "            channels.append(channel_data)\n",
    "            \n",
    "        trials.append(channels)\n",
    "        \n",
    "    subjects[subject]['X'] = np.array(trials)\n",
    "    subjects[subject]['y'] = np.array(subject_data[['subject identifier', 'trial number']]\\\n",
    "                                      .drop_duplicates()['subject identifier'])\n",
    "\n",
    "#Create folder structure and save the clean data\n",
    "if not os.path.exists(os.path.join('Datasets_clean', 'Alcoholism_S1')):\n",
    "    os.makedirs(os.path.join('Datasets_clean', 'Alcoholism_S1'))\n",
    "\n",
    "with open(os.path.join('Datasets_clean', 'Alcoholism_S1', 'clean_data.pkl'), 'wb') as handle:\n",
    "    pickle.dump(subjects, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FingerMovements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T13:20:25.809412Z",
     "start_time": "2020-11-26T13:20:18.888154Z"
    }
   },
   "outputs": [],
   "source": [
    "#Read data\n",
    "data_train = {}\n",
    "data_test = {}\n",
    "\n",
    "for i in range(1,29):\n",
    "    data_train[i] = arff.loadarff(os.path.join('Datasets_raw', \n",
    "                                               'FingerMovements',\n",
    "                                               f'FingerMovementsDimension{i}_TRAIN.arff'))[0]\n",
    "    data_test[i] = arff.loadarff(os.path.join('Datasets_raw', \n",
    "                                               'FingerMovements',\n",
    "                                               f'FingerMovementsDimension{i}_TEST.arff'))[0]\n",
    "\n",
    "#Convert to pandas dataframes\n",
    "df_train = timeseries_to_pandas(data_train)\n",
    "df_test = timeseries_to_pandas(data_test)\n",
    "\n",
    "#Convert to numpy arrays\n",
    "X_train, y_train = pandas_to_numpy(df_train)\n",
    "X_test, y_test = pandas_to_numpy(df_test)\n",
    "\n",
    "#Create folder structure and save the arrays\n",
    "if not os.path.exists(os.path.join('Datasets_clean', 'FingerMovements')):\n",
    "    os.makedirs(os.path.join('Datasets_clean', 'FingerMovements'))\n",
    "\n",
    "np.save('Datasets_clean/FingerMovements/X_train', X_train)\n",
    "np.save('Datasets_clean/FingerMovements/y_train', y_train)\n",
    "np.save('Datasets_clean/FingerMovements/X_test', X_test)\n",
    "np.save('Datasets_clean/FingerMovements/y_test', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SelfregulationSCP1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T13:22:16.954519Z",
     "start_time": "2020-11-26T13:22:05.553992Z"
    }
   },
   "outputs": [],
   "source": [
    "#Read data\n",
    "data_train = {}\n",
    "data_test = {}\n",
    "\n",
    "for i in range(1,7):\n",
    "    data_train[i] = arff.loadarff(os.path.join('Datasets_raw', \n",
    "                                               'SelfRegulationSCP1',\n",
    "                                               f'SelfRegulationSCP1Dimension{i}_TRAIN.arff'))[0]\n",
    "    data_test[i] = arff.loadarff(os.path.join('Datasets_raw', \n",
    "                                               'SelfRegulationSCP1',\n",
    "                                               f'SelfRegulationSCP1Dimension{i}_TEST.arff'))[0]\n",
    "    \n",
    "#Convert to pandas dataframes\n",
    "df_train = timeseries_to_pandas(data_train)\n",
    "df_test = timeseries_to_pandas(data_test)\n",
    "\n",
    "#Convert to numpy arrays\n",
    "X_train, y_train = pandas_to_numpy(df_train)\n",
    "X_test, y_test = pandas_to_numpy(df_test)\n",
    "\n",
    "#Create folder structure and save the arrays\n",
    "if not os.path.exists(os.path.join('Datasets_clean', 'SelfRegulationSCP1')):\n",
    "    os.makedirs(os.path.join('Datasets_clean', 'SelfRegulationSCP1'))\n",
    "\n",
    "np.save('Datasets_clean/SelfRegulationSCP1/X_train', X_train)\n",
    "np.save('Datasets_clean/SelfRegulationSCP1/y_train', y_train)\n",
    "np.save('Datasets_clean/SelfRegulationSCP1/X_test', X_test)\n",
    "np.save('Datasets_clean/SelfRegulationSCP1/y_test', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T13:33:51.286398Z",
     "start_time": "2020-11-26T13:32:28.757522Z"
    }
   },
   "outputs": [],
   "source": [
    "#Create a dictionary to store, for each subject, a numpy array of all his trials \n",
    "#in the format (n_trials, n_channels, n_timesteps), and a numpy array with the \n",
    "#identifier of the subject ('c' for control, 'a' for alcoholic) for each\n",
    "#of his trials\n",
    "subjects = {}\n",
    "i = 1\n",
    "\n",
    "for file in os.listdir(\"./Datasets_raw/DEAP/data_preprocessed_python\"):\n",
    "    if file.endswith(\".dat\"):\n",
    "        data = pickle.load(open('Datasets_raw/DEAP/data_preprocessed_python/{}'.format(file), 'rb'), encoding='latin1')\n",
    "        \n",
    "        #EEG timeseries\n",
    "        all_timeseries = data['data'].copy()\n",
    "        eeg_timeseries = all_timeseries[:,0:32,:]\n",
    "        \n",
    "        #Response variables\n",
    "        valence = data['labels'][:,0]\n",
    "        valence = np.digitize(valence,np.array([0,5]))\n",
    "        valence[valence == 1] = 0\n",
    "        valence[valence == 2] = 1\n",
    "        \n",
    "        arousal = data['labels'][:,1]\n",
    "        arousal = np.digitize(arousal,np.array([0,5]))\n",
    "        arousal[arousal == 1] = 0\n",
    "        arousal[arousal == 2] = 1\n",
    "        \n",
    "        dominance = data['labels'][:,2]\n",
    "        dominance = np.digitize(dominance,np.array([0,5]))\n",
    "        dominance[dominance == 1] = 0\n",
    "        dominance[dominance == 2] = 1\n",
    "        \n",
    "        liking = data['labels'][:,3]\n",
    "        liking = np.digitize(liking,np.array([0,5]))\n",
    "        liking[liking == 1] = 0\n",
    "        liking[liking == 2] = 1\n",
    "        \n",
    "        #Save the subject dadta\n",
    "        subjects[f'subject_{i}'] = {}\n",
    "        subjects[f'subject_{i}']['X'] = eeg_timeseries\n",
    "        subjects[f'subject_{i}']['y_valence'] = valence\n",
    "        subjects[f'subject_{i}']['y_arousal'] = arousal\n",
    "        subjects[f'subject_{i}']['y_dominance'] = dominance\n",
    "        subjects[f'subject_{i}']['y_liking'] = liking\n",
    "\n",
    "        i = i+1\n",
    "        \n",
    "#Create folder structure and save the clean data\n",
    "if not os.path.exists(os.path.join('Datasets_clean', 'DEAP')):\n",
    "    os.makedirs(os.path.join('Datasets_clean', 'DEAP'))\n",
    "\n",
    "with open(os.path.join('Datasets_clean', 'DEAP', 'clean_data.pkl'), 'wb') as handle:\n",
    "    pickle.dump(subjects, handle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_survey",
   "language": "python",
   "name": "eeg_survey"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
