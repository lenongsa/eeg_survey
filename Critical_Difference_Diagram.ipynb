{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-21T02:34:59.729481Z",
     "start_time": "2020-11-21T02:34:59.265632Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-21T02:34:59.741365Z",
     "start_time": "2020-11-21T02:34:59.731297Z"
    }
   },
   "outputs": [],
   "source": [
    "deap = pd.read_csv('results/Scores_DEAP_Valence.csv')\n",
    "alcoholism = pd.read_csv('results/Scores_Alcoholism_S1.csv')\n",
    "scp1 = pd.read_csv('results/Scores_SelfregulationSCP1.csv')\n",
    "fingermov = pd.read_csv('results/Scores_FingerMovements.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-21T02:39:10.938738Z",
     "start_time": "2020-11-21T02:39:10.923894Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'pyeeg_lr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-9662659a0f98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdeap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdeap_clf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/var/python/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   2353\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2354\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2355\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2357\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer (pandas/_libs/lib.c:66645)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-9662659a0f98>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdeap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdeap_clf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'pyeeg_lr'"
     ]
    }
   ],
   "source": [
    "deap.method.apply(lambda x: deap_clf[str(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-21T02:40:18.212709Z",
     "start_time": "2020-11-21T02:40:18.160827Z"
    }
   },
   "outputs": [],
   "source": [
    "deap_clf = {'pyeeg_lr' : 'FS + LR',\n",
    "          'pyeeg_svc' : 'FS + SVM',\n",
    "          'pyeeg_rf' : 'FS + RF',\n",
    "          'pyeeg_lgbm' : 'FS + GBT',\n",
    "          'it_acc' : 'InceptionTime',\n",
    "          'cnn_acc' : 'CNN',\n",
    "          'wm_lr' : 'WM + LR',\n",
    "          'wm_svc' : 'WM + SVM',\n",
    "          'wm_rf' : 'WM + RF',\n",
    "          'wm_lgbm' : 'WM + GBT',\n",
    "          'dtw_acc' : 'DTW + 1NN'}\n",
    "\n",
    "deap['method'] = deap.method.apply(lambda x: deap_clf[x])\n",
    "\n",
    "alcoholism_clf = {'pyeeg_lr' : 'FS + LR',\n",
    "                  'pyeeg_svc' : 'FS + SVM',\n",
    "                  'pyeeg_rf' : 'FS + RF',\n",
    "                  'pyeeg_lgbm' : 'FS + GBT',\n",
    "                  'dl_it' : 'InceptionTime',\n",
    "                  'dl_cnn' : 'CNN',\n",
    "                  'wm_lr' : 'WM + LR',\n",
    "                  'wm_svc' : 'WM + SVM',\n",
    "                  'wm_rf' : 'WM + RF',\n",
    "                  'wm_lgbm' : 'WM + GBT',\n",
    "                  'dtw_knn' : 'DTW + 1NN'}\n",
    "\n",
    "alcoholism['method'] = alcoholism.method.apply(lambda x: alcoholism_clf[x])\n",
    "scp1['method'] = scp1.method.apply(lambda x: alcoholism_clf[x])\n",
    "fingermov['method'] = fingermov.method.apply(lambda x: alcoholism_clf[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-21T02:42:32.717582Z",
     "start_time": "2020-11-21T02:42:32.628744Z"
    }
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "a = pd.DataFrame()\n",
    "for df in [deap, alcoholism, scp1, fingermov,\n",
    "           deap, alcoholism, scp1, fingermov,\n",
    "           deap, alcoholism, scp1, fingermov,\n",
    "           deap, alcoholism, scp1, fingermov]:\n",
    "    i+=1\n",
    "    df = df.rename(columns = {'method' : 'classifier_name',\n",
    "                              'mean' : 'accuracy'})\n",
    "    df = df.drop('std', axis = 1)\n",
    "    df['dataset_name'] = str(i)\n",
    "    a = pd.concat([a,df])\n",
    "    \n",
    "a.to_csv('cd-diagram/example.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-21T02:42:35.052825Z",
     "start_time": "2020-11-21T02:42:35.047725Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-21T02:41:50.045686Z",
     "start_time": "2020-11-21T02:41:50.039008Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FS + RF          12\n",
       "FS + GBT         12\n",
       "WM + LR          12\n",
       "InceptionTime    12\n",
       "FS + SVM         12\n",
       "WM + SVM         12\n",
       "WM + RF          12\n",
       "DTW + 1NN        12\n",
       "CNN              12\n",
       "WM + GBT         12\n",
       "FS + LR          12\n",
       "Name: classifier_name, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.classifier_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-21T02:28:50.718175Z",
     "start_time": "2020-11-21T02:28:50.714586Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fingermov.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-21T02:28:22.935617Z",
     "start_time": "2020-11-21T02:28:22.928445Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyeeg_svc     4\n",
       "pyeeg_lgbm    4\n",
       "wm_svc        4\n",
       "pyeeg_lr      4\n",
       "wm_lgbm       4\n",
       "pyeeg_rf      4\n",
       "wm_lr         4\n",
       "wm_rf         4\n",
       "dtw_knn       3\n",
       "dl_it         3\n",
       "dl_cnn        3\n",
       "cnn_acc       1\n",
       "dtw_acc       1\n",
       "it_acc        1\n",
       "Name: classifier_name, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.classifier_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-21T02:15:34.602935Z",
     "start_time": "2020-11-21T02:15:29.928427Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'DefaultvsTunedvsEnsembleCritDiffAcc.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-fc6469c3828d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    378\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mp_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage_ranks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_nb_datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m \u001b[0mdf_perf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DefaultvsTunedvsEnsembleCritDiffAcc.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0mdraw_cd_diagram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_perf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_perf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/var/python/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/var/python/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/var/python/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/var/python/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/var/python/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas/_libs/parsers.c:4209)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas/_libs/parsers.c:8873)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'DefaultvsTunedvsEnsembleCritDiffAcc.csv' does not exist"
     ]
    }
   ],
   "source": [
    "# Author: Hassan Ismail Fawaz <hassan.ismail-fawaz@uha.fr>\n",
    "#         Germain Forestier <germain.forestier@uha.fr>\n",
    "#         Jonathan Weber <jonathan.weber@uha.fr>\n",
    "#         Lhassane Idoumghar <lhassane.idoumghar@uha.fr>\n",
    "#         Pierre-Alain Muller <pierre-alain.muller@uha.fr>\n",
    "# License: GPL3\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matplotlib.rcParams['font.family'] = 'sans-serif'\n",
    "matplotlib.rcParams['font.sans-serif'] = 'Arial'\n",
    "\n",
    "import operator\n",
    "import math\n",
    "from scipy.stats import wilcoxon\n",
    "from scipy.stats import friedmanchisquare\n",
    "import networkx\n",
    "\n",
    "# inspired from orange3 https://docs.orange.biolab.si/3/data-mining-library/reference/evaluation.cd.html\n",
    "def graph_ranks(avranks, names, p_values, cd=None, cdmethod=None, lowv=None, highv=None,\n",
    "                width=6, textspace=1, reverse=False, filename=None, labels=False, **kwargs):\n",
    "    \"\"\"\n",
    "    Draws a CD graph, which is used to display  the differences in methods'\n",
    "    performance. See Janez Demsar, Statistical Comparisons of Classifiers over\n",
    "    Multiple Data Sets, 7(Jan):1--30, 2006.\n",
    "\n",
    "    Needs matplotlib to work.\n",
    "\n",
    "    The image is ploted on `plt` imported using\n",
    "    `import matplotlib.pyplot as plt`.\n",
    "\n",
    "    Args:\n",
    "        avranks (list of float): average ranks of methods.\n",
    "        names (list of str): names of methods.\n",
    "        cd (float): Critical difference used for statistically significance of\n",
    "            difference between methods.\n",
    "        cdmethod (int, optional): the method that is compared with other methods\n",
    "            If omitted, show pairwise comparison of methods\n",
    "        lowv (int, optional): the lowest shown rank\n",
    "        highv (int, optional): the highest shown rank\n",
    "        width (int, optional): default width in inches (default: 6)\n",
    "        textspace (int, optional): space on figure sides (in inches) for the\n",
    "            method names (default: 1)\n",
    "        reverse (bool, optional):  if set to `True`, the lowest rank is on the\n",
    "            right (default: `False`)\n",
    "        filename (str, optional): output file name (with extension). If not\n",
    "            given, the function does not write a file.\n",
    "        labels (bool, optional): if set to `True`, the calculated avg rank\n",
    "        values will be displayed\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import matplotlib\n",
    "        import matplotlib.pyplot as plt\n",
    "        from matplotlib.backends.backend_agg import FigureCanvasAgg\n",
    "    except ImportError:\n",
    "        raise ImportError(\"Function graph_ranks requires matplotlib.\")\n",
    "\n",
    "    width = float(width)\n",
    "    textspace = float(textspace)\n",
    "\n",
    "    def nth(l, n):\n",
    "        \"\"\"\n",
    "        Returns only nth elemnt in a list.\n",
    "        \"\"\"\n",
    "        n = lloc(l, n)\n",
    "        return [a[n] for a in l]\n",
    "\n",
    "    def lloc(l, n):\n",
    "        \"\"\"\n",
    "        List location in list of list structure.\n",
    "        Enable the use of negative locations:\n",
    "        -1 is the last element, -2 second last...\n",
    "        \"\"\"\n",
    "        if n < 0:\n",
    "            return len(l[0]) + n\n",
    "        else:\n",
    "            return n\n",
    "\n",
    "    def mxrange(lr):\n",
    "        \"\"\"\n",
    "        Multiple xranges. Can be used to traverse matrices.\n",
    "        This function is very slow due to unknown number of\n",
    "        parameters.\n",
    "\n",
    "        >>> mxrange([3,5])\n",
    "        [(0, 0), (0, 1), (0, 2), (1, 0), (1, 1), (1, 2)]\n",
    "\n",
    "        >>> mxrange([[3,5,1],[9,0,-3]])\n",
    "        [(3, 9), (3, 6), (3, 3), (4, 9), (4, 6), (4, 3)]\n",
    "\n",
    "        \"\"\"\n",
    "        if not len(lr):\n",
    "            yield ()\n",
    "        else:\n",
    "            # it can work with single numbers\n",
    "            index = lr[0]\n",
    "            if isinstance(index, int):\n",
    "                index = [index]\n",
    "            for a in range(*index):\n",
    "                for b in mxrange(lr[1:]):\n",
    "                    yield tuple([a] + list(b))\n",
    "\n",
    "    def print_figure(fig, *args, **kwargs):\n",
    "        canvas = FigureCanvasAgg(fig)\n",
    "        canvas.print_figure(*args, **kwargs)\n",
    "\n",
    "    sums = avranks\n",
    "\n",
    "    nnames = names\n",
    "    ssums = sums\n",
    "\n",
    "    if lowv is None:\n",
    "        lowv = min(1, int(math.floor(min(ssums))))\n",
    "    if highv is None:\n",
    "        highv = max(len(avranks), int(math.ceil(max(ssums))))\n",
    "\n",
    "    cline = 0.4\n",
    "\n",
    "    k = len(sums)\n",
    "\n",
    "    lines = None\n",
    "\n",
    "    linesblank = 0\n",
    "    scalewidth = width - 2 * textspace\n",
    "\n",
    "    def rankpos(rank):\n",
    "        if not reverse:\n",
    "            a = rank - lowv\n",
    "        else:\n",
    "            a = highv - rank\n",
    "        return textspace + scalewidth / (highv - lowv) * a\n",
    "\n",
    "    distanceh = 0.25\n",
    "\n",
    "    cline += distanceh\n",
    "\n",
    "    # calculate height needed height of an image\n",
    "    minnotsignificant = max(2 * 0.2, linesblank)\n",
    "    height = cline + ((k + 1) / 2) * 0.2 + minnotsignificant\n",
    "\n",
    "    fig = plt.figure(figsize=(width, height))\n",
    "    fig.set_facecolor('white')\n",
    "    ax = fig.add_axes([0, 0, 1, 1])  # reverse y axis\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    hf = 1. / height  # height factor\n",
    "    wf = 1. / width\n",
    "\n",
    "    def hfl(l):\n",
    "        return [a * hf for a in l]\n",
    "\n",
    "    def wfl(l):\n",
    "        return [a * wf for a in l]\n",
    "\n",
    "    # Upper left corner is (0,0).\n",
    "    ax.plot([0, 1], [0, 1], c=\"w\")\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(1, 0)\n",
    "\n",
    "    def line(l, color='k', **kwargs):\n",
    "        \"\"\"\n",
    "        Input is a list of pairs of points.\n",
    "        \"\"\"\n",
    "        ax.plot(wfl(nth(l, 0)), hfl(nth(l, 1)), color=color, **kwargs)\n",
    "\n",
    "    def text(x, y, s, *args, **kwargs):\n",
    "        ax.text(wf * x, hf * y, s, *args, **kwargs)\n",
    "\n",
    "    line([(textspace, cline), (width - textspace, cline)], linewidth=2)\n",
    "\n",
    "    bigtick = 0.3\n",
    "    smalltick = 0.15\n",
    "    linewidth = 2.0\n",
    "    linewidth_sign = 4.0\n",
    "\n",
    "    tick = None\n",
    "    for a in list(np.arange(lowv, highv, 0.5)) + [highv]:\n",
    "        tick = smalltick\n",
    "        if a == int(a):\n",
    "            tick = bigtick\n",
    "        line([(rankpos(a), cline - tick / 2),\n",
    "              (rankpos(a), cline)],\n",
    "             linewidth=2)\n",
    "\n",
    "    for a in range(lowv, highv + 1):\n",
    "        text(rankpos(a), cline - tick / 2 - 0.05, str(a),\n",
    "             ha=\"center\", va=\"bottom\", size=16)\n",
    "\n",
    "    k = len(ssums)\n",
    "\n",
    "    def filter_names(name):\n",
    "        return name\n",
    "\n",
    "    space_between_names = 0.24\n",
    "\n",
    "    for i in range(math.ceil(k / 2)):\n",
    "        chei = cline + minnotsignificant + i * space_between_names\n",
    "        line([(rankpos(ssums[i]), cline),\n",
    "              (rankpos(ssums[i]), chei),\n",
    "              (textspace - 0.1, chei)],\n",
    "             linewidth=linewidth)\n",
    "        if labels:\n",
    "            text(textspace + 0.3, chei - 0.075, format(ssums[i], '.4f'), ha=\"right\", va=\"center\", size=10)\n",
    "        text(textspace - 0.2, chei, filter_names(nnames[i]), ha=\"right\", va=\"center\", size=16)\n",
    "\n",
    "    for i in range(math.ceil(k / 2), k):\n",
    "        chei = cline + minnotsignificant + (k - i - 1) * space_between_names\n",
    "        line([(rankpos(ssums[i]), cline),\n",
    "              (rankpos(ssums[i]), chei),\n",
    "              (textspace + scalewidth + 0.1, chei)],\n",
    "             linewidth=linewidth)\n",
    "        if labels:\n",
    "            text(textspace + scalewidth - 0.3, chei - 0.075, format(ssums[i], '.4f'), ha=\"left\", va=\"center\", size=10)\n",
    "        text(textspace + scalewidth + 0.2, chei, filter_names(nnames[i]),\n",
    "             ha=\"left\", va=\"center\", size=16)\n",
    "\n",
    "    # no-significance lines\n",
    "    def draw_lines(lines, side=0.05, height=0.1):\n",
    "        start = cline + 0.2\n",
    "\n",
    "        for l, r in lines:\n",
    "            line([(rankpos(ssums[l]) - side, start),\n",
    "                  (rankpos(ssums[r]) + side, start)],\n",
    "                 linewidth=linewidth_sign)\n",
    "            start += height\n",
    "            print('drawing: ', l, r)\n",
    "\n",
    "    # draw_lines(lines)\n",
    "    start = cline + 0.2\n",
    "    side = -0.02\n",
    "    height = 0.1\n",
    "\n",
    "    # draw no significant lines\n",
    "    # get the cliques\n",
    "    cliques = form_cliques(p_values, nnames)\n",
    "    i = 1\n",
    "    achieved_half = False\n",
    "    print(nnames)\n",
    "    for clq in cliques:\n",
    "        if len(clq) == 1:\n",
    "            continue\n",
    "        print(clq)\n",
    "        min_idx = np.array(clq).min()\n",
    "        max_idx = np.array(clq).max()\n",
    "        if min_idx >= len(nnames) / 2 and achieved_half == False:\n",
    "            start = cline + 0.25\n",
    "            achieved_half = True\n",
    "        line([(rankpos(ssums[min_idx]) - side, start),\n",
    "              (rankpos(ssums[max_idx]) + side, start)],\n",
    "             linewidth=linewidth_sign)\n",
    "        start += height\n",
    "\n",
    "\n",
    "def form_cliques(p_values, nnames):\n",
    "    \"\"\"\n",
    "    This method forms the cliques\n",
    "    \"\"\"\n",
    "    # first form the numpy matrix data\n",
    "    m = len(nnames)\n",
    "    g_data = np.zeros((m, m), dtype=np.int64)\n",
    "    for p in p_values:\n",
    "        if p[3] == False:\n",
    "            i = np.where(nnames == p[0])[0][0]\n",
    "            j = np.where(nnames == p[1])[0][0]\n",
    "            min_i = min(i, j)\n",
    "            max_j = max(i, j)\n",
    "            g_data[min_i, max_j] = 1\n",
    "\n",
    "    g = networkx.Graph(g_data)\n",
    "    return networkx.find_cliques(g)\n",
    "\n",
    "\n",
    "def draw_cd_diagram(df_perf=None, alpha=0.05, title=None, labels=False):\n",
    "    \"\"\"\n",
    "    Draws the critical difference diagram given the list of pairwise classifiers that are\n",
    "    significant or not\n",
    "    \"\"\"\n",
    "    p_values, average_ranks, _ = wilcoxon_holm(df_perf=df_perf, alpha=alpha)\n",
    "\n",
    "    print(average_ranks)\n",
    "\n",
    "    for p in p_values:\n",
    "        print(p)\n",
    "\n",
    "\n",
    "    graph_ranks(average_ranks.values, average_ranks.keys(), p_values,\n",
    "                cd=None, reverse=True, width=9, textspace=1.5, labels=labels)\n",
    "\n",
    "    font = {'family': 'sans-serif',\n",
    "        'color':  'black',\n",
    "        'weight': 'normal',\n",
    "        'size': 22,\n",
    "        }\n",
    "    if title:\n",
    "        plt.title(title,fontdict=font, y=0.9, x=0.5)\n",
    "    plt.savefig('cd-diagram.png',bbox_inches='tight')\n",
    "\n",
    "def wilcoxon_holm(alpha=0.05, df_perf=None):\n",
    "    \"\"\"\n",
    "    Applies the wilcoxon signed rank test between each pair of algorithm and then use Holm\n",
    "    to reject the null's hypothesis\n",
    "    \"\"\"\n",
    "    print(pd.unique(df_perf['classifier_name']))\n",
    "    # count the number of tested datasets per classifier\n",
    "    df_counts = pd.DataFrame({'count': df_perf.groupby(\n",
    "        ['classifier_name']).size()}).reset_index()\n",
    "    # get the maximum number of tested datasets\n",
    "    max_nb_datasets = df_counts['count'].max()\n",
    "    # get the list of classifiers who have been tested on nb_max_datasets\n",
    "    classifiers = list(df_counts.loc[df_counts['count'] == max_nb_datasets]\n",
    "                       ['classifier_name'])\n",
    "    # test the null hypothesis using friedman before doing a post-hoc analysis\n",
    "    friedman_p_value = friedmanchisquare(*(\n",
    "        np.array(df_perf.loc[df_perf['classifier_name'] == c]['accuracy'])\n",
    "        for c in classifiers))[1]\n",
    "    if friedman_p_value >= alpha:\n",
    "        # then the null hypothesis over the entire classifiers cannot be rejected\n",
    "        print('the null hypothesis over the entire classifiers cannot be rejected')\n",
    "        exit()\n",
    "    # get the number of classifiers\n",
    "    m = len(classifiers)\n",
    "    # init array that contains the p-values calculated by the Wilcoxon signed rank test\n",
    "    p_values = []\n",
    "    # loop through the algorithms to compare pairwise\n",
    "    for i in range(m - 1):\n",
    "        # get the name of classifier one\n",
    "        classifier_1 = classifiers[i]\n",
    "        # get the performance of classifier one\n",
    "        perf_1 = np.array(df_perf.loc[df_perf['classifier_name'] == classifier_1]['accuracy']\n",
    "                          , dtype=np.float64)\n",
    "        for j in range(i + 1, m):\n",
    "            # get the name of the second classifier\n",
    "            classifier_2 = classifiers[j]\n",
    "            # get the performance of classifier one\n",
    "            perf_2 = np.array(df_perf.loc[df_perf['classifier_name'] == classifier_2]\n",
    "                              ['accuracy'], dtype=np.float64)\n",
    "            # calculate the p_value\n",
    "            p_value = wilcoxon(perf_1, perf_2, zero_method='pratt')[1]\n",
    "            # appen to the list\n",
    "            p_values.append((classifier_1, classifier_2, p_value, False))\n",
    "    # get the number of hypothesis\n",
    "    k = len(p_values)\n",
    "    # sort the list in acsending manner of p-value\n",
    "    p_values.sort(key=operator.itemgetter(2))\n",
    "\n",
    "    # loop through the hypothesis\n",
    "    for i in range(k):\n",
    "        # correct alpha with holm\n",
    "        new_alpha = float(alpha / (k - i))\n",
    "        # test if significant after holm's correction of alpha\n",
    "        if p_values[i][2] <= new_alpha:\n",
    "            p_values[i] = (p_values[i][0], p_values[i][1], p_values[i][2], True)\n",
    "        else:\n",
    "            # stop\n",
    "            break\n",
    "    # compute the average ranks to be returned (useful for drawing the cd diagram)\n",
    "    # sort the dataframe of performances\n",
    "    sorted_df_perf = df_perf.loc[df_perf['classifier_name'].isin(classifiers)]. \\\n",
    "        sort_values(['classifier_name', 'dataset_name'])\n",
    "    # get the rank data\n",
    "    rank_data = np.array(sorted_df_perf['accuracy']).reshape(m, max_nb_datasets)\n",
    "\n",
    "    # create the data frame containg the accuracies\n",
    "    df_ranks = pd.DataFrame(data=rank_data, index=np.sort(classifiers), columns=\n",
    "    np.unique(sorted_df_perf['dataset_name']))\n",
    "\n",
    "    # number of wins\n",
    "    dfff = df_ranks.rank(ascending=False)\n",
    "    print(dfff[dfff == 1.0].sum(axis=1))\n",
    "\n",
    "    # average the ranks\n",
    "    average_ranks = df_ranks.rank(ascending=False).mean(axis=1).sort_values(ascending=False)\n",
    "    # return the p-values and the average ranks\n",
    "    return p_values, average_ranks, max_nb_datasets\n",
    "\n",
    "df_perf = pd.read_csv('DefaultvsTunedvsEnsembleCritDiffAcc.csv',index_col=False)\n",
    "\n",
    "draw_cd_diagram(df_perf=df_perf, title='Accuracy', labels=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
